{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from scipy.optimize import minimize_scalar, minimize\n",
    "from IPython.display import Latex\n",
    "from stargazer.stargazer import Stargazer\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a python port of some of the code in \"Learning Microeconometrics with R\" by Christopher P Adams. It corresponds to the blog post: https://nathanielf.github.io//post/mle_utility_and_choice/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revealed Preference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Revealed Preference Axiom ** If there are two choices, A and B, and we\n",
    "observe a person choose A, then her utility from A is greater than her utility\n",
    "from B.\n",
    "\n",
    "So in a simple binary case we can estimate the utility from differences expresed over the purchase prices.When $A$ is purchased over $B$ we know that \n",
    "\n",
    "$$ u_A - p_A < u_B - p_B $$ \n",
    "\n",
    "Normalising to a particular reference price, say B, We set $p = p_A - p_B$ and $utility = u_A - u_B$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.236"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1000\n",
    "np.random.seed(0)\n",
    "u = np.random.normal(0, 3, N)\n",
    "u = np.sort(u)\n",
    "p_B = 2\n",
    "# Share cases where utility is positive i.e. where A is chosen\n",
    "np.mean(u - p_B > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple example of where we can use assumptions of revealed preference and a hypothetical range of utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x149dc7198>"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random distribution of price points\n",
    "p = np.random.uniform(-10, 10, N)\n",
    "share_empirical = np.zeros(shape=(len(p), 1))\n",
    "share_theoretical = np.zeros(shape=(len(p), 1))\n",
    "ecdf = ECDF(u)\n",
    "for i in range(0, len(p)):\n",
    "    # share of market with a positive utility for A over B at a given price point\n",
    "    share_empirical[i] = np.mean(u-p[i] > 0)\n",
    "\n",
    "# Get the Empirical cdf fro U\n",
    "share_theoretical = 1-ecdf(u)\n",
    "    \n",
    "\n",
    "pd.DataFrame({'share_empirical': share_empirical.flatten(), 'p': p}).plot(x='share_empirical',\n",
    "                                                                          y='p', kind=\"scatter\", \n",
    "                                                                          title=\"Price by Estimated Shares\")\n",
    "\n",
    "pd.DataFrame({'share_theoretical': share_theoretical.flatten(), 'u':u }).plot(x='share_theoretical', \n",
    "                                                                                             y='u', kind=\"scatter\", \n",
    "                                                                                title=\"Utility by Theoretical Shares\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However in both cases we made use of the fact that we knew the distribution of the utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem: Modelling Discrete Choice by Latent Utility Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some assumptions about the form of the utility distribution are crucial as our modeling efforts will go wrong if we know nothing about the latent utilities. We assume that the latent utility can be expressed as by the revealed preferences i.e. as the share or proportion of choices made by the customers.\n",
    "\n",
    "The utility is some function of product and consumer's properties, perhaps mostly driven by price\n",
    "\n",
    "$$ utility = \\mathbf{X'}\\beta + e$$\n",
    "\n",
    "and market share is an expression of that utility\n",
    "$$ demand_A = utility_{A} > 0 $$\n",
    "\n",
    "In a choice context we're trying to determine if the implicit utility measure is sufficient to drive a purchase, and as such OLS models are inappropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.200\n",
      "Model:                            OLS   Adj. R-squared:                  0.198\n",
      "Method:                 Least Squares   F-statistic:                     124.5\n",
      "Date:                Sat, 20 Feb 2021   Prob (F-statistic):           5.42e-49\n",
      "Time:                        16:01:07   Log-Likelihood:                 58.448\n",
      "No. Observations:                1000   AIC:                            -110.9\n",
      "Df Residuals:                     997   BIC:                            -96.17\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const             0.2095      0.040      5.291      0.000       0.132       0.287\n",
      "product_desc      0.1120      0.013      8.939      0.000       0.087       0.137\n",
      "product_desc1    -0.1045      0.008    -12.630      0.000      -0.121      -0.088\n",
      "==============================================================================\n",
      "Omnibus:                      472.919   Durbin-Watson:                   1.983\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1999.877\n",
      "Skew:                           2.298   Prob(JB):                         0.00\n",
      "Kurtosis:                       8.183   Cond. No.                         23.8\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "const            0.20953\n",
      "product_desc     0.11204\n",
      "product_desc1   -0.10449\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "a = 2\n",
    "b = -3\n",
    "e = np.random.normal(0, 1, N)\n",
    "consumer_desc = np.random.uniform(3, 1, N)\n",
    "consumer_desc1 = np.random.uniform(2, 5, N)\n",
    "utility = 2 + 3*consumer_desc + -4*consumer_desc1 + e\n",
    "## Predicting choice over two options\n",
    "demand_A = utility > 0\n",
    "X = pd.DataFrame({'product_desc': consumer_desc, 'product_desc1': consumer_desc1})\n",
    "X = sm.add_constant(X)\n",
    "lm1 = sm.OLS(demand_A,X)\n",
    "lm1_results = lm1.fit()\n",
    "print(lm1_results.summary())\n",
    "print(round(lm1_results.params, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This stems from the fact that we're'trying to estimate a conditional probability over a binary choice not a continuous measure. The revealed preference assumption says that we can predict the purchase if the utility of good is positive.\n",
    "\n",
    "$$Pr(demand_A = 1) = utility > 0 $$ \n",
    "$$= Pr(\\mathbf{X'}\\beta + e > 0) $$\n",
    "$$ = Pr(e > - \\mathbf{X'}\\beta ) $$\n",
    "$$ = 1 - F(\\mathbf{X'}\\beta ) $$\n",
    "\n",
    "where $F$ is the distribution of the unobserved random variable $e$. The challenge is using the correct distribution as this feeds the method of statistical estimation of the parameters $\\beta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Likelihood Fits over Candidate Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of candidate distributions which might serve to replace $F$ and estimate the share of purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fun: 64.10354778811556\n",
      " hess_inv: <1x1 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([0.])\n",
      "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 16\n",
      "      nit: 6\n",
      "     njev: 8\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([0.33999999])\n"
     ]
    }
   ],
   "source": [
    "def log_binomial_dist(params, *args):\n",
    "    p = params[0]\n",
    "    p_hat = args[0]\n",
    "    N = args[1]\n",
    "    return -((p_hat*N)*np.log(p) + (1-p_hat)*N*np.log(1-(p)))\n",
    "\n",
    "res = minimize(log_binomial_dist, x0 = [.1], args =(.34, 100), bounds = ((0, .99),))\n",
    "print(res)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " final_simplex: (array([[1.27170093, 0.28846111, 4.97078397, 2.33608166, 0.98080792],\n",
      "       [1.27163611, 0.28845751, 4.97079439, 2.33611095, 0.98081281],\n",
      "       [1.27179597, 0.28845924, 4.97076792, 2.33606271, 0.98080085],\n",
      "       [1.27178217, 0.28845315, 4.97077749, 2.33606068, 0.98081083],\n",
      "       [1.2716755 , 0.28844586, 4.97079715, 2.33609652, 0.98080788],\n",
      "       [1.27174903, 0.28845715, 4.97077654, 2.33606353, 0.98081551]]), array([1399.55005084, 1399.55005089, 1399.55005094, 1399.55005095,\n",
      "       1399.55005095, 1399.55005106]))\n",
      "           fun: 1399.5500508414766\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 384\n",
      "           nit: 238\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.27170093, 0.28846111, 4.97078397, 2.33608166, 0.98080792])\n"
     ]
    }
   ],
   "source": [
    "def ll_ols(params, *args):\n",
    "    X, y = args[0], args[1]\n",
    "    beta = [params[0], params[1], params[2]]\n",
    "    mu, sd, = params[3], params[4]\n",
    "    z = (y - X.dot(beta)) / sd\n",
    "    log_lik = -sum(np.log(stats.norm.pdf(z)) - np.log(sd))\n",
    "    return log_lik\n",
    "\n",
    "x = np.random.normal(5, 2, 1000)\n",
    "x1 = np.random.normal(6, 1, 1000)\n",
    "x2 = np.random.uniform(2, 7, 1000)\n",
    "y = 1 + .3*x + 5*x1 + np.random.normal(0, 1, 1000)\n",
    "\n",
    "X1 = pd.DataFrame({'consumer_desc': x, 'consumer_desc1': x1})\n",
    "X1 = sm.add_constant(X1)\n",
    "\n",
    "res = minimize(ll_ols, x0 =[2, 1, 4, 2, 1], method = 'Nelder-Mead', args =(X1, y))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 94.044202\n",
      "         Iterations: 17\n",
      "         Function evaluations: 108\n",
      "         Gradient evaluations: 18\n",
      "      fun: 94.04420183563171\n",
      " hess_inv: array([[ 0.72799404, -0.03552851, -0.26060106,  0.        ,  0.        ],\n",
      "       [-0.03552851,  0.09513159, -0.08023828,  0.        ,  0.        ],\n",
      "       [-0.26060106, -0.08023828,  0.18756252,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ,  1.        ]])\n",
      "      jac: array([ 3.81469727e-06, -9.53674316e-06,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "     nfev: 108\n",
      "      nit: 17\n",
      "     njev: 18\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 2.14197608,  2.42768647, -3.51990129,  0.        ,  1.        ])\n"
     ]
    }
   ],
   "source": [
    "def log_probit_dist(params, *args):\n",
    "    X, y = args[0], args[1]\n",
    "    beta = [params[0], params[1], params[2]]\n",
    "    mu, sd, = params[3], params[4]\n",
    "    Xb = X.dot(beta)\n",
    "    q = 2*y-1\n",
    "    log_lik = np.log(stats.norm.cdf(q*Xb))\n",
    "    return -sum(log_lik)\n",
    "\n",
    "### Optimise the probit model for determining the parameters required toe estimate the underlying utility\n",
    "### True values of the parameters 2, 3, -4\n",
    "res = minimize(log_probit_dist, x0 =[0, 0 ,0 , 0, 1], args =(X, demand_A), options={'disp': True})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These estimates are still incorrect but an awful lot closer than the fits achieved by the ols model in the first section. We can validate the above optimisation against the inbuilt model of statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.094044\n",
      "         Iterations 10\n",
      "Parameters:  const            2.141972\n",
      "product_desc     2.427687\n",
      "product_desc1   -3.519900\n",
      "dtype: float64\n",
      "Marginal effects: \n",
      "       Probit Marginal Effects       \n",
      "=====================================\n",
      "Dep. Variable:                      y\n",
      "Method:                          dydx\n",
      "At:                           overall\n",
      "=================================================================================\n",
      "                   dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "product_desc      0.1285      0.011     12.137      0.000       0.108       0.149\n",
      "product_desc1    -0.1863      0.015    -12.674      0.000      -0.215      -0.157\n",
      "=================================================================================\n"
     ]
    }
   ],
   "source": [
    "probit_mod = sm.Probit(demand_A, X)\n",
    "probit_res = probit_mod.fit()\n",
    "probit_margeff = probit_res.get_margeff()\n",
    "print('Parameters: ', probit_res.params)\n",
    "print('Marginal effects: ')\n",
    "print(probit_margeff.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## McFaddan's BART Discrete Choice Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is a generalisation of the above to estimate the difference in utilities across multiple products. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ U_{i,j} = \\mathbf{X'}_{i, j}\\beta + v_{i,j} $$\n",
    "\n",
    "where the each individual's $i$ utility for a given good $j$ is expressed as a linear weighted function of the product characteristics $\\mathbf{X}$. Since we need to predict demand based on utility we're really interested in estimating the differnce in utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$U_{i,A} > U_{i, B} $$\n",
    "\n",
    "just when \n",
    "\n",
    "$$ \\mathbf{X'}_{i, A}\\beta + v_{i,A} > \\mathbf{X'}_{i, B}\\beta + v_{i,B}$$\n",
    "\n",
    "or \n",
    "\n",
    "$$  v_{i,A} -  v_{i,B} > - (\\mathbf{X'}_{i, A}  - \\mathbf{X'}_{i, B})\\beta $$\n",
    "\n",
    "but then the probability of demand is just \n",
    "\n",
    "$$Pr(demand_A = 1 | \\mathbf{X'}_{i, A}, \\mathbf{X'}_{i, B}) = Pr\\Bigg( v_{i,A} -  v_{i,B} > - (\\mathbf{X'}_{i, A}  - \\mathbf{X'}_{i, B})\\beta \\Bigg) $$\n",
    "$$ = Pr\\Bigg( -v_{i,A} -  v_{i,B} < (\\mathbf{X'}_{i, A}  - \\mathbf{X'}_{i, B})\\beta \\Bigg) $$\n",
    "$$ = F\\Bigg( (\\mathbf{X'}_{i, A}  - \\mathbf{X'}_{i, B})\\beta \\Bigg) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Example in Two Products & Two Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 100\n",
    "X_A = sm.add_constant(np.random.rand(N,2))\n",
    "X_B = sm.add_constant(np.random.rand(N, 2))\n",
    "beta = np.array([1, -2, 3])\n",
    "\n",
    "#probit we only need one normal error term since sums of normals are normal\n",
    "v = np.random.normal(0, 1, N)\n",
    "y = (X_A.dot(beta) - X_B.dot(beta)) + v > 0\n",
    "X_diff = X_A - X_B\n",
    "X_diff[:, 0] =  1\n",
    "X_diff = pd.DataFrame(X_diff, columns=['const', 'product_desc', 'product_desc1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we can try two classification algorithms which attempt to characterise the error terms $v_{1}, v_{2}$ that the McFaddan model assumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.426413\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "probit_mod = sm.Probit(y, X_diff)\n",
    "probit_res = probit_mod.fit()\n",
    "probit_margeff = probit_res.get_margeff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.499093\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "v1 = np.random.weibull(1, N)\n",
    "v2 = np.random.weibull(1, N)\n",
    "y = (X_A.dot(beta) - X_B.dot(beta)) + (v1 - v2) > 0\n",
    "logit_mod = sm.Logit(y, X_diff)\n",
    "logit_res = logit_mod.fit()\n",
    "logit_margeff = logit_res.get_margeff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\"></td><td colspan=\"2\"><em>Dependent variable:y</em></td></tr><tr><td style=\"text-align:left\"></td><tr><td></td><td colspan=\"1\">Probit Model</td><td colspan=\"1\">Logit Model</td></tr><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td></tr><tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\">const</td><td>-0.255<sup></sup></td><td>-0.049<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.156)</td><td>(0.246)</td></tr><tr><td style=\"text-align:left\">product_desc</td><td>-1.491<sup>***</sup></td><td>-2.157<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.445)</td><td>(0.690)</td></tr><tr><td style=\"text-align:left\">product_desc1</td><td>2.964<sup>***</sup></td><td>3.833<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.578)</td><td>(0.888)</td></tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Observations</td><td>100</td><td>100</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td></td><td></td></tr><tr><td style=\"text-align: left\">Adjusted R<sup>2</sup></td><td></td><td></td></tr><tr><td style=\"text-align: left\">Residual Std. Error</td><td>1.000 (df=97)</td><td>1.000 (df=97)</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td><sup></sup> (df=2; 97)</td><td><sup></sup> (df=2; 97)</td></tr><tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td>\n",
       " <td colspan=\"2\" style=\"text-align: right\">\n",
       "  <sup>*</sup>p&lt;0.1;\n",
       "  <sup>**</sup>p&lt;0.05;\n",
       "  <sup>***</sup>p&lt;0.01\n",
       " </td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stargazer = Stargazer([probit_res, logit_res])\n",
    "stargazer.custom_columns(['Probit Model', 'Logit Model'], [1, 1])\n",
    "#stargazer.add_custom_notes([str(probit_margeff.summary()), str(logit_margeff.summary())])\n",
    "HTML(stargazer.render_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalising to Multiple choices: The Multinomial Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 542.609688\n",
      "         Iterations: 185\n",
      "         Function evaluations: 338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " final_simplex: (array([[-1.74855767, -5.18018459,  7.07552039],\n",
       "       [-1.74856002, -5.18016799,  7.07549515],\n",
       "       [-1.74856866, -5.18022325,  7.07555337],\n",
       "       [-1.74862589, -5.18016727,  7.07561422]]), array([542.60968847, 542.60968847, 542.60968848, 542.60968848]))\n",
       "           fun: 542.6096884689198\n",
       "       message: 'Optimization terminated successfully.'\n",
       "          nfev: 338\n",
       "           nit: 185\n",
       "        status: 0\n",
       "       success: True\n",
       "             x: array([-1.74855767, -5.18018459,  7.07552039])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "N = 1000\n",
    "mu = [0,0]\n",
    "rho = 0.1\n",
    "cov = [[1, rho], [rho, 1]]\n",
    "\n",
    "# u is N*2\n",
    "u = np.random.multivariate_normal(mu, cov, 1000)\n",
    "x1 = np.random.uniform(0, 1, size=(N,2)) #np.random.rand(N,2)\n",
    "x2 = np.random.uniform(0, 1, size=(N,2)) #np.random.rand(N,2)\n",
    "\n",
    "U = -1 + -3*x1 + 4*x2 + u\n",
    "\n",
    "y = np.zeros(shape=(N, 2))\n",
    "y[:,0] = ((U[:,0] > 0) & (U[:,0] > U[:,1]))\n",
    "y[:,1] = (U[:,1] > 0 & (U[:,1] > U[:,0]))\n",
    "\n",
    "\n",
    "W1 = pd.DataFrame({'x1':x1[:,0], 'x2':x2[:,0]})\n",
    "W2 = pd.DataFrame({'x1':x1[:,1], 'x2':x2[:,1]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.630391\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>MNLogit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>   <td>  2000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                <td>MNLogit</td>     <th>  Df Residuals:      </th>   <td>  1994</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     4</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 25 Feb 2021</td> <th>  Pseudo R-squ.:     </th>   <td>0.2924</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>21:23:52</td>     <th>  Log-Likelihood:    </th>  <td> -1260.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th>  <td> -1781.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>2.587e-224</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>y=class_1</th>    <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>     <td>   -2.6666</td> <td>    0.219</td> <td>  -12.201</td> <td> 0.000</td> <td>   -3.095</td> <td>   -2.238</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>        <td>   -4.7724</td> <td>    0.315</td> <td>  -15.143</td> <td> 0.000</td> <td>   -5.390</td> <td>   -4.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>        <td>    6.2800</td> <td>    0.360</td> <td>   17.461</td> <td> 0.000</td> <td>    5.575</td> <td>    6.985</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>y=class_2</th>    <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>     <td>   -2.7293</td> <td>    0.212</td> <td>  -12.865</td> <td> 0.000</td> <td>   -3.145</td> <td>   -2.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>        <td>   -4.4876</td> <td>    0.299</td> <td>  -15.004</td> <td> 0.000</td> <td>   -5.074</td> <td>   -3.901</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>        <td>    6.4438</td> <td>    0.348</td> <td>   18.497</td> <td> 0.000</td> <td>    5.761</td> <td>    7.127</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                          MNLogit Regression Results                          \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                 2000\n",
       "Model:                        MNLogit   Df Residuals:                     1994\n",
       "Method:                           MLE   Df Model:                            4\n",
       "Date:                Thu, 25 Feb 2021   Pseudo R-squ.:                  0.2924\n",
       "Time:                        21:23:52   Log-Likelihood:                -1260.8\n",
       "converged:                       True   LL-Null:                       -1781.9\n",
       "Covariance Type:            nonrobust   LLR p-value:                2.587e-224\n",
       "==============================================================================\n",
       " y=class_1       coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -2.6666      0.219    -12.201      0.000      -3.095      -2.238\n",
       "x1            -4.7724      0.315    -15.143      0.000      -5.390      -4.155\n",
       "x2             6.2800      0.360     17.461      0.000       5.575       6.985\n",
       "------------------------------------------------------------------------------\n",
       " y=class_2       coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -2.7293      0.212    -12.865      0.000      -3.145      -2.313\n",
       "x1            -4.4876      0.299    -15.004      0.000      -5.074      -3.901\n",
       "x2             6.4438      0.348     18.497      0.000       5.761       7.127\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_full = np.ones(shape=(N*2,1))\n",
    "class_1 = np.where(((U[:,0] > 0) & (U[:,0] > U[:,1])), 'class_1', 'class_0')\n",
    "class_2 = np.where((U[:,1] > 0 & (U[:,1] > U[:,0])), 'class_2', 'class_0')\n",
    "y_full = np.append(class_1, class_2)\n",
    "W_full = sm.add_constant(W1.append(W2)).reset_index(drop=True)\n",
    "mn_logit = sm.MNLogit(y_full, W_full)\n",
    "mn_logit_res = mn_logit.fit()\n",
    "mn_logit_res.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 1260.782799\n",
      "         Iterations: 21\n",
      "         Function evaluations: 470\n",
      "         Gradient evaluations: 47\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      fun: 1260.782798764732\n",
       " hess_inv: array([[ 1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.15840199,  0.05230628,\n",
       "        -0.24846581,  0.08569624, -0.08026449, -0.11217585],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.05230628,  0.05960721,\n",
       "        -0.11533024,  0.03950015, -0.02890953, -0.06618335],\n",
       "       [ 0.        ,  0.        ,  0.        , -0.24846581, -0.11533024,\n",
       "         0.42805566, -0.14239161,  0.11728476,  0.20865474],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.08569624,  0.03950015,\n",
       "        -0.14239161,  0.0776523 , -0.03556134, -0.10565188],\n",
       "       [ 0.        ,  0.        ,  0.        , -0.08026449, -0.02890953,\n",
       "         0.11728476, -0.03556134,  0.07906259,  0.01257425],\n",
       "       [ 0.        ,  0.        ,  0.        , -0.11217585, -0.06618335,\n",
       "         0.20865474, -0.10565188,  0.01257425,  0.18307424]])\n",
       "      jac: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.05175781e-05,\n",
       "       1.52587891e-05, 0.00000000e+00, 3.05175781e-05, 3.05175781e-05,\n",
       "       3.05175781e-05])\n",
       "  message: 'Desired error not necessarily achieved due to precision loss.'\n",
       "     nfev: 470\n",
       "      nit: 21\n",
       "     njev: 47\n",
       "   status: 2\n",
       "  success: False\n",
       "        x: array([ 0.09640129,  0.00798646,  0.70648002, -2.66658562, -4.77244682,\n",
       "        6.27997417, -2.72927898, -4.48757328,  6.44379724])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "def cdf(W, beta):\n",
    "    Wb = np.dot(W, beta)\n",
    "    eXB = np.exp(Wb)\n",
    "    eXB = eXB /eXB.sum(1)[:, None]\n",
    "    return eXB\n",
    "\n",
    "def take_log(probs):\n",
    "    epsilon = 1e-20 \n",
    "    return np.log(probs)\n",
    "\n",
    "def calc_ll(logged, d):\n",
    "    ll = d * logged\n",
    "    return ll\n",
    "\n",
    "def ll_mn_logistic(params, *args):\n",
    "    y, W, n_params, n_classes = args[0], args[1], args[2], args[3]\n",
    "    beta = [params[i] for i in range(0, len(params))]\n",
    "    beta = np.array(beta).reshape(n_params, -1, order='F')\n",
    "    beta[:,0] = [0 for i in range(0, n_params)]\n",
    "    \n",
    "    ## onehot_encode\n",
    "    d = pd.get_dummies(y, prefix='Flag').to_numpy()\n",
    "    \n",
    "    probs = cdf(W, beta)\n",
    "    logged = take_log(probs)\n",
    "    ll = calc_ll(logged, d)\n",
    "    \n",
    "    return -np.sum(ll)\n",
    "\n",
    "n_params = 3 \n",
    "n_classes = 3\n",
    "z = np.random.rand(3,3).flatten()\n",
    "#probs = ll_mn_logistic(list(z), *[y_full, W_full, n_params, n_classes])\n",
    "\n",
    "\n",
    "res = minimize(ll_mn_logistic, x0 =z, args =(y_full, W_full, n_params, n_classes), \n",
    "             options={'disp': True, 'maxiter':1000})\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HOUSEID</th>\n",
       "      <th>TRAVDAY</th>\n",
       "      <th>SAMPSTRAT</th>\n",
       "      <th>HOMEOWN</th>\n",
       "      <th>HHSIZE</th>\n",
       "      <th>HHVEHCNT</th>\n",
       "      <th>HHFAMINC</th>\n",
       "      <th>PC</th>\n",
       "      <th>SPHONE</th>\n",
       "      <th>TAB</th>\n",
       "      <th>...</th>\n",
       "      <th>SMPLSRCE</th>\n",
       "      <th>WTHHFIN</th>\n",
       "      <th>HBHUR</th>\n",
       "      <th>HTHTNRNT</th>\n",
       "      <th>HTPPOPDN</th>\n",
       "      <th>HTRESDN</th>\n",
       "      <th>HTEEMPDN</th>\n",
       "      <th>HBHTNRNT</th>\n",
       "      <th>HBPPOPDN</th>\n",
       "      <th>HBRESDN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000007</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>187.314320</td>\n",
       "      <td>T</td>\n",
       "      <td>50</td>\n",
       "      <td>1500</td>\n",
       "      <td>750</td>\n",
       "      <td>750</td>\n",
       "      <td>20</td>\n",
       "      <td>750</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30000008</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>69.513032</td>\n",
       "      <td>R</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>150</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30000012</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>79.419586</td>\n",
       "      <td>C</td>\n",
       "      <td>80</td>\n",
       "      <td>17000</td>\n",
       "      <td>17000</td>\n",
       "      <td>5000</td>\n",
       "      <td>60</td>\n",
       "      <td>17000</td>\n",
       "      <td>7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30000019</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>279.143588</td>\n",
       "      <td>S</td>\n",
       "      <td>40</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>750</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30000029</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>103.240304</td>\n",
       "      <td>S</td>\n",
       "      <td>40</td>\n",
       "      <td>1500</td>\n",
       "      <td>750</td>\n",
       "      <td>750</td>\n",
       "      <td>40</td>\n",
       "      <td>1500</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    HOUSEID  TRAVDAY  SAMPSTRAT  HOMEOWN  HHSIZE  HHVEHCNT  HHFAMINC  PC  \\\n",
       "0  30000007        2          3        1       3         5         7   2   \n",
       "1  30000008        5          2        1       2         4         8   1   \n",
       "2  30000012        5          3        1       1         2        10   1   \n",
       "3  30000019        5          3        1       2         2         3   1   \n",
       "4  30000029        3          3        1       2         2         5   2   \n",
       "\n",
       "   SPHONE  TAB  ...  SMPLSRCE     WTHHFIN  HBHUR  HTHTNRNT  HTPPOPDN  HTRESDN  \\\n",
       "0       1    2  ...         2  187.314320      T        50      1500      750   \n",
       "1       1    2  ...         2   69.513032      R         5       300      300   \n",
       "2       1    3  ...         2   79.419586      C        80     17000    17000   \n",
       "3       5    5  ...         2  279.143588      S        40       300      300   \n",
       "4       5    1  ...         2  103.240304      S        40      1500      750   \n",
       "\n",
       "   HTEEMPDN  HBHTNRNT  HBPPOPDN  HBRESDN  \n",
       "0       750        20       750      300  \n",
       "1       150         5       300      300  \n",
       "2      5000        60     17000     7000  \n",
       "3       150        50       750      300  \n",
       "4       750        40      1500      750  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart_data = pd.read_csv('../data_files/mcfaddan_bart.csv')\n",
    "bart_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathanielforde/.local/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/Users/nathanielforde/.local/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HOUSEID</th>\n",
       "      <th>TRAVDAY</th>\n",
       "      <th>SAMPSTRAT</th>\n",
       "      <th>HOMEOWN</th>\n",
       "      <th>HHSIZE</th>\n",
       "      <th>HHVEHCNT</th>\n",
       "      <th>HHFAMINC</th>\n",
       "      <th>PC</th>\n",
       "      <th>SPHONE</th>\n",
       "      <th>TAB</th>\n",
       "      <th>...</th>\n",
       "      <th>HBRESDN</th>\n",
       "      <th>CHOICE</th>\n",
       "      <th>car1</th>\n",
       "      <th>train1</th>\n",
       "      <th>home</th>\n",
       "      <th>income</th>\n",
       "      <th>density</th>\n",
       "      <th>urban1</th>\n",
       "      <th>rail</th>\n",
       "      <th>row_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30000008</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>300</td>\n",
       "      <td>car</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30000085</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>17000</td>\n",
       "      <td>nan</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>30000130</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>...</td>\n",
       "      <td>17000</td>\n",
       "      <td>rail</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>30000144</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3000</td>\n",
       "      <td>bus</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>30000145</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3000</td>\n",
       "      <td>car</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129674</th>\n",
       "      <td>40794087</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>...</td>\n",
       "      <td>3000</td>\n",
       "      <td>car</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129688</th>\n",
       "      <td>40794241</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3000</td>\n",
       "      <td>car</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129690</th>\n",
       "      <td>40794260</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1500</td>\n",
       "      <td>car</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129693</th>\n",
       "      <td>40794294</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>7000</td>\n",
       "      <td>car</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129695</th>\n",
       "      <td>50515573</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>17000</td>\n",
       "      <td>nan</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39057 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         HOUSEID  TRAVDAY  SAMPSTRAT  HOMEOWN  HHSIZE  HHVEHCNT  HHFAMINC  PC  \\\n",
       "1       30000008        5          2        1       2         4         8   1   \n",
       "9       30000085        1          2        1       1         2         9   1   \n",
       "15      30000130        1          1        1       2         1         5  -9   \n",
       "17      30000144        3          2        2       3         0         5   5   \n",
       "18      30000145        5          2        2       2         2         7   1   \n",
       "...          ...      ...        ...      ...     ...       ...       ...  ..   \n",
       "129674  40794087        2          1        2       1         1         5   2   \n",
       "129688  40794241        3          2        1       2         2         6   1   \n",
       "129690  40794260        5          2        1       4         1        11   1   \n",
       "129693  40794294        5          2        1       2         2        10   1   \n",
       "129695  50515573        3          1        1       1         0        10   1   \n",
       "\n",
       "        SPHONE  TAB  ...  HBRESDN  CHOICE   car1  train1  home  income  \\\n",
       "1            1    2  ...      300     car   True   False   1.0     8.0   \n",
       "9            1    4  ...    17000     nan  False   False   1.0     9.0   \n",
       "15           1   -9  ...    17000    rail  False    True   1.0     5.0   \n",
       "17           1    1  ...     3000     bus  False   False   0.0     5.0   \n",
       "18           1    2  ...     3000     car   True   False   0.0     7.0   \n",
       "...        ...  ...  ...      ...     ...    ...     ...   ...     ...   \n",
       "129674      -9   -9  ...     3000     car   True   False   0.0     5.0   \n",
       "129688       1    5  ...     3000     car   True   False   1.0     6.0   \n",
       "129690       1    2  ...     1500     car   True   False   1.0    11.0   \n",
       "129693       1    5  ...     7000     car   True   False   1.0    10.0   \n",
       "129695       1    5  ...    17000     nan  False   False   1.0    10.0   \n",
       "\n",
       "        density  urban1   rail  row_sum  \n",
       "1           0.3   False  False    False  \n",
       "9          17.0    True  False    False  \n",
       "15         30.0    True   True    False  \n",
       "17          3.0    True  False    False  \n",
       "18          7.0    True  False    False  \n",
       "...         ...     ...    ...      ...  \n",
       "129674      7.0    True   True    False  \n",
       "129688      7.0    True  False    False  \n",
       "129690      3.0    True  False    False  \n",
       "129693      7.0    True  False    False  \n",
       "129695     30.0    True   True    False  \n",
       "\n",
       "[39057 rows x 67 columns]"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart_data['CHOICE'] = np.nan\n",
    "bart_data['CHOICE'] = np.where(bart_data['CAR']==1, 'car', bart_data['CHOICE'])\n",
    "bart_data['CHOICE'] = np.where(bart_data['BUS']==1, 'bus', bart_data['CHOICE'])\n",
    "bart_data['CHOICE'] = np.where(bart_data['TRAIN']==1, 'rail', bart_data['CHOICE'])\n",
    "bart_data['car1'] = bart_data['CHOICE'] == 'car'\n",
    "bart_data['train1'] = bart_data['CHOICE'] == 'rail'\n",
    "bart_data['home'] = np.where(bart_data['HOMEOWN'] == 1, 1, np.nan)\n",
    "bart_data['home'] = np.where(bart_data['HOMEOWN'] > 1, 0, bart_data['home'])\n",
    "bart_data['income'] = np.where(bart_data['HHFAMINC'] > 0, bart_data['HHFAMINC'], np.nan)\n",
    "bart_data['density'] = np.where(bart_data['HTPPOPDN']==-9, np.nan, bart_data['HTPPOPDN']/1000)\n",
    "bart_data['urban1'] = bart_data['URBAN']==1\n",
    "y = bart_data[(bart_data['WRKCOUNT'] > 0) & ((bart_data['MSACAT'] == 1) | (bart_data['MSACAT'] == 2))]\n",
    "y['rail'] = y['RAIL'] == 1\n",
    "y['row_sum'] = y[['car1','train1','home','HHSIZE','income', 'urban1','density','MSACAT', 'rail']].sum(axis=1) == 0\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathanielforde/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rail</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>car1</th>\n",
       "      <td>0.973861</td>\n",
       "      <td>0.877925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train1</th>\n",
       "      <td>0.010036</td>\n",
       "      <td>0.096610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home</th>\n",
       "      <td>0.749231</td>\n",
       "      <td>0.730127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HHSIZE</th>\n",
       "      <td>2.462420</td>\n",
       "      <td>2.487870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>7.054552</td>\n",
       "      <td>7.518840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>urban1</th>\n",
       "      <td>0.869753</td>\n",
       "      <td>0.910272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density</th>\n",
       "      <td>4.661936</td>\n",
       "      <td>7.559076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rail        False     True \n",
       "car1     0.973861  0.877925\n",
       "train1   0.010036  0.096610\n",
       "home     0.749231  0.730127\n",
       "HHSIZE   2.462420  2.487870\n",
       "income   7.054552  7.518840\n",
       "urban1   0.869753  0.910272\n",
       "density  4.661936  7.559076"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\"car1\",\"train1\",\"home\",\"HHSIZE\",\"income\",\"urban1\",\"density\", 'rail', 'CHOICE']\n",
    "y_focus = y[features]\n",
    "y_focus.dropna(inplace=True)\n",
    "y_focus = y_focus[y_focus['CHOICE'] != 'nan']\n",
    "y_focus[features].groupby('rail').mean().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home</th>\n",
       "      <th>HHSIZE</th>\n",
       "      <th>income</th>\n",
       "      <th>urban1</th>\n",
       "      <th>density</th>\n",
       "      <th>CHOICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.3</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>30.0</td>\n",
       "      <td>rail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>bus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129667</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.3</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129674</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129688</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129690</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129693</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34043 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        home  HHSIZE  income  urban1  density CHOICE\n",
       "1        1.0       2     8.0   False      0.3    car\n",
       "15       1.0       2     5.0    True     30.0   rail\n",
       "17       0.0       3     5.0    True      3.0    bus\n",
       "18       0.0       2     7.0    True      7.0    car\n",
       "33       1.0       3    11.0    True      1.5    car\n",
       "...      ...     ...     ...     ...      ...    ...\n",
       "129667   1.0       2     8.0   False      0.3    car\n",
       "129674   0.0       1     5.0    True      7.0    car\n",
       "129688   1.0       2     6.0    True      7.0    car\n",
       "129690   1.0       4    11.0    True      3.0    car\n",
       "129693   1.0       2    10.0    True      7.0    car\n",
       "\n",
       "[34043 rows x 6 columns]"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_focus[features + ['CHOICE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.114130\n",
      "         Iterations 9\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.300803\n",
      "         Iterations 7\n"
     ]
    }
   ],
   "source": [
    "# Without Rail\n",
    "y_focus_nr = y_focus[y_focus['rail'] == 0]\n",
    "y_focus_r = y_focus[y_focus['rail'] == 1]\n",
    "\n",
    "\n",
    "logit_mod_nr = sm.Logit(np.array(y_focus_nr['car1']), \n",
    "                       sm.add_constant(y_focus_nr[[\"home\",\"HHSIZE\",\"income\",\"urban1\",\"density\"]]).astype(float))\n",
    "logit_res_nr = logit_mod_nr.fit()\n",
    "logit_margeff_nr = logit_res_nr.get_margeff()\n",
    "\n",
    "\n",
    "logit_mod_r = sm.Logit(np.array(y_focus_r['car1']), \n",
    "                       sm.add_constant(y_focus_r[[\"home\",\"HHSIZE\",\"income\",\"urban1\",\"density\"]]).astype(float))\n",
    "logit_res_r = logit_mod_r.fit()\n",
    "logit_margeff_r = logit_res.get_margeff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\"></td><td colspan=\"2\"><em>Dependent variable:y</em></td></tr><tr><td style=\"text-align:left\"></td><tr><td></td><td colspan=\"1\">Probability of Car - No Rail</td><td colspan=\"1\">Probability of Car -Rail</td></tr><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td></tr><tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\">HHSIZE</td><td>-0.018<sup></sup></td><td>0.050<sup>*</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.033)</td><td>(0.026)</td></tr><tr><td style=\"text-align:left\">const</td><td>3.775<sup>***</sup></td><td>3.506<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.270)</td><td>(0.211)</td></tr><tr><td style=\"text-align:left\">density</td><td>-0.055<sup>***</sup></td><td>-0.109<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.008)</td><td>(0.003)</td></tr><tr><td style=\"text-align:left\">home</td><td>0.633<sup>***</sup></td><td>0.498<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.095)</td><td>(0.071)</td></tr><tr><td style=\"text-align:left\">income</td><td>0.133<sup>***</sup></td><td>-0.068<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.019)</td><td>(0.013)</td></tr><tr><td style=\"text-align:left\">urban1</td><td>-1.160<sup>***</sup></td><td>-0.312<sup>*</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.246)</td><td>(0.187)</td></tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Observations</td><td>22,419</td><td>11,624</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td></td><td></td></tr><tr><td style=\"text-align: left\">Adjusted R<sup>2</sup></td><td></td><td></td></tr><tr><td style=\"text-align: left\">Residual Std. Error</td><td>1.000 (df=22413)</td><td>1.000 (df=11618)</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td><sup></sup> (df=5; 22413)</td><td><sup></sup> (df=5; 11618)</td></tr><tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td>\n",
       " <td colspan=\"2\" style=\"text-align: right\">\n",
       "  <sup>*</sup>p&lt;0.1;\n",
       "  <sup>**</sup>p&lt;0.05;\n",
       "  <sup>***</sup>p&lt;0.01\n",
       " </td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stargazer = Stargazer([logit_res_nr, logit_res_r])\n",
    "stargazer.custom_columns(['Probability of Car - No Rail', 'Probability of Car -Rail'], [1, 1])\n",
    "#stargazer.add_custom_notes([str(probit_margeff.summary()), str(logit_margeff.summary())])\n",
    "HTML(stargazer.render_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.387108\n",
      "         Iterations 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>MNLogit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>   <td> 11624</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                <td>MNLogit</td>     <th>  Df Residuals:      </th>   <td> 11614</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     8</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Fri, 26 Feb 2021</td> <th>  Pseudo R-squ.:     </th>   <td>0.1071</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>00:45:00</td>     <th>  Log-Likelihood:    </th>  <td> -4499.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th>  <td> -5039.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>9.100e-228</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <th>y=car</th>     <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>home</th>    <td>    1.0460</td> <td>    0.128</td> <td>    8.159</td> <td> 0.000</td> <td>    0.795</td> <td>    1.297</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HHSIZE</th>  <td>    0.2411</td> <td>    0.046</td> <td>    5.234</td> <td> 0.000</td> <td>    0.151</td> <td>    0.331</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income</th>  <td>    0.2235</td> <td>    0.021</td> <td>   10.829</td> <td> 0.000</td> <td>    0.183</td> <td>    0.264</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>urban1</th>  <td>    1.7447</td> <td>    0.150</td> <td>   11.619</td> <td> 0.000</td> <td>    1.450</td> <td>    2.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>density</th> <td>   -0.0847</td> <td>    0.006</td> <td>  -13.677</td> <td> 0.000</td> <td>   -0.097</td> <td>   -0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>y=rail</th>     <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>home</th>    <td>    0.3757</td> <td>    0.140</td> <td>    2.689</td> <td> 0.007</td> <td>    0.102</td> <td>    0.650</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HHSIZE</th>  <td>   -0.0495</td> <td>    0.051</td> <td>   -0.973</td> <td> 0.331</td> <td>   -0.149</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income</th>  <td>    0.1658</td> <td>    0.022</td> <td>    7.466</td> <td> 0.000</td> <td>    0.122</td> <td>    0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>urban1</th>  <td>   -0.0949</td> <td>    0.167</td> <td>   -0.569</td> <td> 0.569</td> <td>   -0.422</td> <td>    0.232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>density</th> <td>    0.0202</td> <td>    0.007</td> <td>    3.107</td> <td> 0.002</td> <td>    0.007</td> <td>    0.033</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                          MNLogit Regression Results                          \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                11624\n",
       "Model:                        MNLogit   Df Residuals:                    11614\n",
       "Method:                           MLE   Df Model:                            8\n",
       "Date:                Fri, 26 Feb 2021   Pseudo R-squ.:                  0.1071\n",
       "Time:                        00:45:00   Log-Likelihood:                -4499.7\n",
       "converged:                       True   LL-Null:                       -5039.6\n",
       "Covariance Type:            nonrobust   LLR p-value:                9.100e-228\n",
       "==============================================================================\n",
       "     y=car       coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "home           1.0460      0.128      8.159      0.000       0.795       1.297\n",
       "HHSIZE         0.2411      0.046      5.234      0.000       0.151       0.331\n",
       "income         0.2235      0.021     10.829      0.000       0.183       0.264\n",
       "urban1         1.7447      0.150     11.619      0.000       1.450       2.039\n",
       "density       -0.0847      0.006    -13.677      0.000      -0.097      -0.073\n",
       "------------------------------------------------------------------------------\n",
       "    y=rail       coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "home           0.3757      0.140      2.689      0.007       0.102       0.650\n",
       "HHSIZE        -0.0495      0.051     -0.973      0.331      -0.149       0.050\n",
       "income         0.1658      0.022      7.466      0.000       0.122       0.209\n",
       "urban1        -0.0949      0.167     -0.569      0.569      -0.422       0.232\n",
       "density        0.0202      0.007      3.107      0.002       0.007       0.033\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MN_logit_mod_r = sm.MNLogit(np.array(y_focus_r['CHOICE']), \n",
    "                       y_focus_r[[\"home\",\"HHSIZE\",\"income\",\"urban1\",\"density\"]].astype(float))\n",
    "MN_logit_res_r = MN_logit_mod_r.fit()\n",
    "MN_logit_res_r.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 4499.748263\n",
      "         Iterations: 33\n",
      "         Function evaluations: 896\n",
      "         Gradient evaluations: 56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      fun: 4499.748263266686\n",
       " hess_inv: array([[ 1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.49790461e-02,\n",
       "         1.22239651e-02, -1.08077892e-03, -4.52948507e-02,\n",
       "         9.24499328e-04,  2.18160612e-02,  1.53707043e-02,\n",
       "        -2.13296546e-03, -3.42635201e-02,  5.36330909e-04],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.22239651e-02,\n",
       "         8.71917753e-03, -1.06847160e-03, -2.23203076e-02,\n",
       "         3.46191120e-04,  1.19746027e-02,  1.05025079e-02,\n",
       "        -1.74296384e-03, -1.65180529e-02,  1.47031357e-04],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.08077892e-03,\n",
       "        -1.06847160e-03,  4.43252403e-04,  1.14187551e-03,\n",
       "        -5.55280050e-05, -8.98456837e-04, -1.17483721e-03,\n",
       "         4.60854131e-04,  6.94275713e-04, -3.43435221e-05],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -4.52948507e-02,\n",
       "        -2.23203076e-02,  1.14187551e-03,  8.77146917e-02,\n",
       "        -1.70194689e-03, -4.37327155e-02, -2.84783896e-02,\n",
       "         3.45189389e-03,  6.85283602e-02, -1.05179786e-03],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  9.24499328e-04,\n",
       "         3.46191120e-04, -5.55280050e-05, -1.70194689e-03,\n",
       "         6.40830138e-05,  8.65122620e-04,  4.47609224e-04,\n",
       "        -8.69531233e-05, -1.35865208e-03,  4.78235451e-05],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.18160612e-02,\n",
       "         1.19746027e-02, -8.98456837e-04, -4.37327155e-02,\n",
       "         8.65122620e-04,  2.42731374e-02,  1.45500604e-02,\n",
       "        -2.32279638e-03, -3.32914355e-02,  5.72986223e-04],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.53707043e-02,\n",
       "         1.05025079e-02, -1.17483721e-03, -2.84783896e-02,\n",
       "         4.47609224e-04,  1.45500604e-02,  1.36673618e-02,\n",
       "        -2.18820823e-03, -2.15013079e-02,  1.87660290e-04],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -2.13296546e-03,\n",
       "        -1.74296384e-03,  4.60854131e-04,  3.45189389e-03,\n",
       "        -8.69531233e-05, -2.32279638e-03, -2.18820823e-03,\n",
       "         7.07813187e-04,  1.90500574e-03, -5.20898364e-05],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -3.42635201e-02,\n",
       "        -1.65180529e-02,  6.94275713e-04,  6.85283602e-02,\n",
       "        -1.35865208e-03, -3.32914355e-02, -2.15013079e-02,\n",
       "         1.90500574e-03,  6.33830924e-02, -1.09402475e-03],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  5.36330909e-04,\n",
       "         1.47031357e-04, -3.43435221e-05, -1.05179786e-03,\n",
       "         4.78235451e-05,  5.72986223e-04,  1.87660290e-04,\n",
       "        -5.20898364e-05, -1.09402475e-03,  5.33476436e-05]])\n",
       "      jac: array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  6.10351562e-05, -6.10351562e-05, -6.10351562e-05,\n",
       "        0.00000000e+00, -1.83105469e-04,  6.10351562e-05,  2.44140625e-04,\n",
       "        3.66210938e-04,  6.10351562e-05,  4.88281250e-04])\n",
       "  message: 'Desired error not necessarily achieved due to precision loss.'\n",
       "     nfev: 896\n",
       "      nit: 33\n",
       "     njev: 56\n",
       "   status: 2\n",
       "  success: False\n",
       "        x: array([ 0.98480009,  0.00651008,  0.0863602 ,  0.13983792,  0.32455478,\n",
       "        1.04604352,  0.24109143,  0.22348356,  1.74469334, -0.08468886,\n",
       "        0.3757215 , -0.04946345,  0.16579691, -0.09489807,  0.02024353])"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_params = 5 \n",
    "n_classes = 3\n",
    "z = np.random.rand(n_params,n_classes).flatten()\n",
    "\n",
    "res = minimize(ll_mn_logistic, x0 =z, args =(y_focus_r['CHOICE'], \n",
    "                                             y_focus_r[[\"home\",\"HHSIZE\",\"income\",\"urban1\",\"density\"]].astype(float), n_params, n_classes), \n",
    "             options={'disp': True, 'maxiter':1000})\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathanielforde/.local/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bus</th>\n",
       "      <th>Car</th>\n",
       "      <th>Train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.7</td>\n",
       "      <td>88.5</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Bus   Car  Train\n",
       "0  2.7  88.5    8.8"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nr = y_focus_nr[['home', 'HHSIZE', 'income', 'urban1', 'density', 'rail']].astype(float)\n",
    "r = y_focus_r[['home', 'HHSIZE', 'income', 'urban1', 'density', 'rail']].astype(float)\n",
    "full = y_focus[['home', 'HHSIZE', 'income', 'urban1', 'density', 'rail']].astype(float)\n",
    "nr_nd = nr\n",
    "nr_nd['density'] = 0\n",
    "nr_d = nr\n",
    "nr_d['density'] = r['density'].mean()\n",
    "full_d = full\n",
    "full_d[full_d['rail'] == 0]['density'] = r['density'].mean()\n",
    "\n",
    "\n",
    "res = MN_logit_res_r.predict(full.drop('rail', axis=1)).mean()\n",
    "\n",
    "res = pd.DataFrame(res).T\n",
    "res.columns = ['Bus', 'Car', 'Train']\n",
    "res.round(3) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "examined_algorithms",
   "language": "python",
   "name": "examined_algorithms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
